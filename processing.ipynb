{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## Importar librerias\n",
    "from linares_plot import *\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
    "import itertools\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels\n",
    "import scikit_posthocs as sp\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "### Open data\n",
    "### Concatenate the different shets into one dataframe\n",
    "\n",
    "xls = pd.ExcelFile('C:\\\\Users\\\\David\\\\Documents\\\\GitHub\\\\episodic-memory-magic\\\\4meses.xlsx') ##clean\n",
    "sheets_int = xls.sheet_names[-3:] #Now you can list all sheets in the file ##when doing it for real, [-3:]\n",
    "frames=[]\n",
    "for sheet in sheets_int:\n",
    "    frames.append(pd.read_excel('C:\\\\Users\\\\David\\\\Documents\\\\GitHub\\\\episodic-memory-magic\\\\4meses.xlsx', sheet_name=sheet ))\n",
    "\n",
    "                  \n",
    "df_data = pd.concat(frames, ignore_index=True)\n",
    "print(len(df_data) )## all shets concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## funciones\n",
    "\n",
    "def map_book(tokens): #function to go from list of words to dictionari (take off punctuation and repetitions\n",
    "    words_wp = []\n",
    "    hash_map = {}\n",
    "    if tokens is not None:\n",
    "        for element in tokens:\n",
    "            # Remove Punctuation\n",
    "            word = element.replace(\",\",\"\")\n",
    "            word = word.replace(\".\",\"\")\n",
    "            word = word.replace(\"-\",\"\")\n",
    "            word = word.replace(\")\",\"\")\n",
    "            word = word.replace(\"(\",\"\")\n",
    "            words_wp.append(word)\n",
    "\n",
    "            # Word Exist?\n",
    "            if word in hash_map:\n",
    "                hash_map[word] = hash_map[word] + 1\n",
    "            else:\n",
    "                hash_map[word] = 1\n",
    "\n",
    "        return hash_map, words_wp\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def give_numbers(wordlist): # function to remove stop words\n",
    "    numbers=['1', '2', '22', '23', '3', '4', '5', '6', '7', '8', '9', '0'] \n",
    "    return [w for w in wordlist if w in numbers]\n",
    "\n",
    "\n",
    "def effects_detected(text):\n",
    "    words_all=[]\n",
    "    [words_all.append(  text.split()[n]  ) for n in range( len(text.split()))]\n",
    "    dict_words, list_words = map_book(words_all) #take off the puntuation and take off repetitions\n",
    "    sortedkeys=sorted(dict_words.keys(), key=lambda x:x.lower()) ##list of uniques in alphabetical order \n",
    "    efectos = give_numbers(sortedkeys) # here I do not mind if 5 is reported 3 times, just yes or no.\n",
    "    return efectos, list_words\n",
    "\n",
    "\n",
    "\n",
    "def separate_sentences_by_effect(text):\n",
    "    ## effects detected\n",
    "    efectos, list_words = effects_detected(text)\n",
    "    #start of sentences\n",
    "    start_sentences=[]\n",
    "    for e in efectos:\n",
    "        arr = np.where(np.array(list_words)==e)[0] ## here I care if 2 is reported 3 times. I want all the sentences\n",
    "        for i in range(len(arr)):\n",
    "            start_sentences.append(arr[i])\n",
    "\n",
    "    start_sentences.sort()\n",
    "    start_sentences.insert(len(start_sentences), len(list_words)) ## otherwise you miss the last resport\n",
    "    #get the whole sentence by index\n",
    "    complete_sentences=[]\n",
    "    for ss in range(len(start_sentences)-1):\n",
    "        sentence =  list_words[start_sentences[ss]: start_sentences[ss+1]  ]\n",
    "        sentence = \" \".join(sentence)\n",
    "        complete_sentences.append( sentence)\n",
    "    \n",
    "    ## by definition, each sentence start with a number\n",
    "    dict_by_effect={}\n",
    "    for sentence in complete_sentences:\n",
    "        eff_sent = sentence.split()[0]\n",
    "        if eff_sent not in list(dict_by_effect.keys()):\n",
    "            dict_by_effect[eff_sent]= [ \" \".join(sentence.split()[1:]) ]\n",
    "        else:\n",
    "            dict_by_effect[eff_sent].append( \" \".join(sentence.split()[1:])  )\n",
    "    \n",
    "    ##   \n",
    "    return complete_sentences, dict_by_effect\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saliencias (palabras que se buscan para determinar saliencias)\n",
    "\n",
    "saliencias_1= [['comodín', 'comodin', 'comodí', 'comodi', 'joker',\n",
    "                 'transposición', 'transposition', 'transposició'],\n",
    "               ['estuche', 'estoig', 'buida', 'caja', 'caixa', 'estuche', 'estoig', 'predicció', 'prediccio',\n",
    "                'predicción', 'prediccion', 'case', 'prediction', 'box'],\n",
    "               ['montones',  'montón', 'monton', 'pilas', 'pilons', 'divide', 'divideix', 'mitades', 'mitad', 'meitat', 'media',\n",
    "                'partir', 'dividir', 'piles', 'division', 'half', 'bifurcation', 'realidades', 'realitats', 'pierdes', 'perds',\n",
    "                'realities', 'lose', 'lost', 'miss', 'perder', 'perdiste', 'perdre', 'parte', 'partir', 'dividir', 'cortar',\n",
    "               'bifurcación', 'bifurcació', 'bifurcacions', 'bifurcaciones', 'tiempo', 'temps', 'time', 'vez', 'vegada',\n",
    "                'cortes', 'reductores', 'reducir', 'corte', 'izquierda', 'derecha', 'dividiendo', 'separando', 'mini',\n",
    "               'dividint', 'bifuracción', 'cortando', 'grupos', 'pequeños', 'numero', 'número', 'nombre', 'decreixent',\n",
    "               'izquierdo', 'derecho', 'escapçava', 'mazo'],\n",
    "               ['color', 'blau', 'vermell', 'azul', 'rojo', 'colores', 'dorso', \n",
    "                'detrás', 'detras', 'darrera', 'red', 'blue', 'back', 'blaus',\n",
    "                'backs', 'behind', 'blaves', 'vermelles', 'rojas', 'azules', 'vermella', 'blava'],\n",
    "               ['encore', 'transformación', 'transformació', 'transformation', 'transforman'],\n",
    "              ['as','ace', 'tres', 'three', 'cuatro', 'quatre', 'four', 'cinc', 'cinco', 'five', 'seis', \n",
    "              'sis', 'six', 'siete', 'set', 'seven', 'ocho', 'vuit', 'eight', 'nueve', 'nou', 'nine', 'diez',\n",
    "              'deu', 'ten', 'jota', 'jotas', 'jack', 'dama', 'damas', 'reina', 'reinas', 'queen', 'rey', 'rei', 'reis', 'reyes', \n",
    "               'king', 'picas', 'piques', 'spades', 'treboles', 'tréboles', 'trebol', 'trèbol', 'trèbols', 'trebols', 'culbs',\n",
    "              'diamantes', 'rombos', 'diamants', 'rombes', 'diamonts', 'diamonds', 'corazones', 'corazón', 'cors', 'cor', 'heard',\n",
    "              'heards'],\n",
    "              ['chico', 'noi', 'chica', 'noia', 'raquel']]\n",
    "\n",
    "\n",
    "saliencias_2 = [['cambian', 'frotar', 'avall', 'cambio', 'taula', 'mesa', 'table', 'tapete', 'tapet', 'rug', 'transformar', 'transformació',\n",
    "                 'fregar', 'rub', 'cambiaba', 'canviava', 'cambia', 'canvia', 'canvien', 'cambiar', 'convierte', 'convierten',\n",
    "                 'change', 'changed', 'Change', 'valor', 'value', 'color', 'fregava', 'frotaba', 'frotó', 'rubbed'], \n",
    "                ['aparecían', 'appear', 'aparecer', 'aparecen','salían', 'salian', 'sortien', 'appeared', 'moneda',\n",
    "                 'monedas', 'monedes' , 'coins',  'euros', 'dinero', 'coin', 'money', 'diners', \n",
    "                 'entre', 'between', 'dinerito', 'moendas', 'pequeñas', 'pequeña', 'little'],\n",
    "                ['as','ace', 'tres', 'three', 'cuatro', 'quatre', 'four', 'cinc', 'cinco', 'five', 'seis', \n",
    "              'sis', 'six', 'siete', 'set', 'seven', 'ocho', 'vuit', 'eight', 'nueve', 'nou', 'nine', 'diez',\n",
    "              'deu', 'ten', 'jota', 'jotas', 'jack', 'dama', 'damas', 'reina', 'reinas', 'queen', 'rey', 'rei', 'reis', 'reyes', \n",
    "               'king', 'picas', 'piques', 'spades', 'treboles', 'tréboles', 'trebol', 'trèbol', 'trèbols', 'trebols', 'culbs',\n",
    "              'diamantes', 'rombos', 'diamants', 'rombes', 'diamonts', 'diamonds', 'corazones', 'corazón', 'cors', 'cor', 'heart',\n",
    "              'hearts'],\n",
    "               ['chico', 'noi', 'chica', 'raquel', 'sortir', 'noia', 'salir', 'baixar', 'escenari', 'escenario', 'tarima', 'front'],\n",
    "               ['oportunidades', 'oportunidad', 'oportunitats', 'oportunitat', 'oportunity', 'intentos', 'intents'],\n",
    "               ['desaparecía', 'desaparecer', 'disappear', 'desvanecía', 'desapareixía', 'esfumaba', 'desparecia'],\n",
    "               ['oreja', 'orella', 'orejas', 'orelles', 'ear', 'pelo', 'cabell', 'pelo']]\n",
    "\n",
    "\n",
    "saliencias_3 = [['monedes', 'amagades', 'sota', 'debajo', 'tapades', 'tapadas', 'under', 'hide',\n",
    "                'escondidas', 'cards', 'coins', 'cartas', 'monedas', 'tapades', 'bajo'],\n",
    "               ['viajaban', 'matrix', 'travell', 'movían', 'reunían', 'juntaban', 'separaban', 'Matrix',\n",
    "               'viatjaven', 'viajan', 'movien', 'moviendo','vaitjes', 'movian', 'move', 'moved', 'travelled',\n",
    "               'cambian', 'cambiaban', 'cambiaba','changed', 'change', 'canvia', 'canviava', 'mouen',\n",
    "               'posición', 'position', 'places', 'posició', 'posiciones', 'posicions', 'mateixa', 'pasaban']]\n",
    "\n",
    "\n",
    "saliencias_4 = [['alma', 'invisible', 'soul', 'ànima', 'invisible', 'fake', 'mentira', 'mentida', 'imaginar', 'imaginario',\n",
    "                 'imaginaria', 'imaginary', 'anima', 'esencia', 'essència', 'essencia', 'invisibles', 'invisibles', 'invisible',\n",
    "                 'imaginàries', 'imaginària', 'imaginarias', 'falsa', 'simuli', 'simulada', 'simular', 'lanzaba', \n",
    "                 'imaginariament', 'imaginariamente', 'vola', 'esperit', 'simulant', 'veure', 'simbólica', 'pasaba',\n",
    "                'mímica', 'esperit', 'inexistent'],\n",
    "               ['girada', 'revered', 'reves', 'revés', 'side', 'vuelta', 'turned', 'medio', 'middle', 'mig', 'prediction',\n",
    "               'predicción', 'predicció', 'volta', 'capgirada'],\n",
    "                ['as','ace', 'dos', 'two', 'tres', 'three', 'cuatro', 'quatre', 'four', 'cinc', 'cinco', 'five', 'seis', \n",
    "              'sis', 'six', 'siete', 'set', 'seven', 'ocho', 'vuit', 'eight', 'nueve', 'nou', 'nine', 'diez',\n",
    "              'deu', 'ten', 'jota', 'jotas', 'jack', 'dama', 'damas', 'reina', 'reinas', 'queen', 'rey', 'rei', 'reis', 'reyes', \n",
    "               'king', 'picas', 'piques', 'spades', 'treboles', 'tréboles', 'trebol', 'trèbol', 'trèbols', 'trebols', 'culbs',\n",
    "              'diamantes', 'rombos', 'diamants', 'rombes', 'diamonts', 'diamonds', 'corazones', 'corazón', 'cors', 'cor', 'heart',\n",
    "              'hearts'],\n",
    "               ['chico', 'chica', 'raquel']]\n",
    "\n",
    "\n",
    "saliencias_5 = [['transforman', 'transformen', 'transform', 'cambiaban', 'canviaven', 'changed', 'material', 'old', 'viajes',\n",
    "                'cobre', 'plata', 'copper', 'bronce', 'antiguas', 'silver', 'noves', 'nuevas', 'antigues', 'noves', 'color', \n",
    "                 'colores', 'colors', 'gris', 'marrón', 'plateadas', 'platejades', 'coure', 'platejat', 'manterial'],\n",
    "                ['vaso', 'baso', 'glass', 'taza', 'got', 'tassa', 'mug', 'vas', 'vasos', 'gots', 'cup', 'cups', 'glasses', 'mugs'],\n",
    "                ['mesa', 'table', 'taula', 'mantel', 'trespassaven'],\n",
    "                ['cuerpo', 'mano', 'hand', 'ma', 'mà', 'hands', 'manos', 'mans', 'cos', 'body', 'brazo', 'braç', 'brazos', 'braços'],\n",
    "                ['salir', 'sortir', 'salían', 'sortien', 'quit', 'leave', 'left', 'salia', 'salía', 'sortia', 'revés', 'reves']]\n",
    "\n",
    "\n",
    "saliencias_6 = [['deletreos', 'deletrear', 'deletraba', 'deletreba', 'deletreaba', 'deletreo', 'deltreó', 'deletreando', 'número', 'numero', 'number',\n",
    "                 'letra', 'letras', 'palabra', 'palabras', 'word', 'words', 'lletra', 'paraula', 'paraules', 'mot', 'mots',\n",
    "                 'spell', 'spelling', 'spelled', 'delletrejar', 'delletrejaba', 'delletreja', 'deletrejant', 'lletrejar',\n",
    "                'contar', 'contaba', 'contando', 'comptar', 'comptava', 'comptant', 'comptaven', 'escribiendo', 'escrivint',\n",
    "                'nom', 'nombre', 'deletreadas', 'lletreig', 'deletrea', 'deletrejava', 'delletrejat', 'nominar', 'anomenar',\n",
    "                'cridar', 'deletreandolas', 'deletrreando', 'deletrearla', 'deletrean', 'deletreabas', 'delerejades', 'deletreaba',\n",
    "                'deletreándolas', 'deletrar', 'lletres', 'deletrejar', 'nombra', 'contaban', 'nombrarlas', 'llamando',\n",
    "                'contant'],\n",
    "               ['tres', 'three', 'espectadores', 'spectators', 'people', 'persones', 'espectadors', 'públic', 'public', 'actuantes', \n",
    "                'público', 'publico', 'auditorio', 'auditori'],\n",
    "                ['española', 'spanish', 'espanyola', 'antiga', 'antigua','bastos', 'oros', 'copas', 'espadas'],\n",
    "                ['cualquiera', 'any', 'qualsevol', 'atzar', 'azar', 'random'],\n",
    "                ['fallado', 'salido', 'equivocó', 'falló', 'fallido', 'errores', 'mistakes', 'work', 'mistake', 'error', 'be', 'bien',\n",
    "                'anulado', 'bé', 'sortir', 'fallit', 'mal', 'falla'],\n",
    "               ['chico', 'chica', 'noi', 'noia', 'raquel']]\n",
    "\n",
    "\n",
    "saliencias_7 = [['blanques', 'blanca', 'blancas', 'white', 'blanquear', 'blanco', 'blanc', 'blancos'],\n",
    "               ['Granada', 'granada', 'amigo', 'amic', 'friend', 'andalusa', 'andalús'],\n",
    "               ['tiempo', 'time', 'dimensions', 'dimensiones', 'temps', 'pasado', 'passat', 'past',\n",
    "                'presente', 'present', 'futuro, futur', 'future', 'somnis', 'sueños', 'onírica', 'dreams',\n",
    "               'poema', 'poesía', 'poètico', 'poem', 'poesia', 'historieta'],\n",
    "               ['reunien', 'ruenion', 'deapararecían', 'desparecen', 'reunen', 'reyes', 'ases', 'disappear',\n",
    "               'convertían', 'travell', 'viajan', 'viatgen', 'viatjaven', 'viajaban', 'reunían', 'reunión',\n",
    "               'montón', 'pile', 'montones', 'pila', 'vanish', 'vanished', 'appear', 'aparecían', 'apareixien',\n",
    "               'apareixen', 'aparecen', 'assamblea', 'assembly', 'asamblea', 'aparecido', 'aparescut'],\n",
    "                ['as','ace', 'dos', 'two', 'tres', 'three', 'cuatro', 'quatre', 'four', 'cinc', 'cinco', 'five', 'seis', \n",
    "              'sis', 'six', 'siete', 'set', 'seven', 'ocho', 'vuit', 'eight', 'nueve', 'nou', 'nine', 'diez',\n",
    "              'deu', 'ten', 'jota', 'jotas', 'jack', 'dama', 'damas', 'reina', 'reinas', 'queen', 'rey', 'rei', 'reis', 'reyes', \n",
    "               'king', 'picas', 'piques', 'spades', 'treboles', 'tréboles', 'trebol', 'trèbol', 'trèbols', 'trebols', 'culbs',\n",
    "              'diamantes', 'rombos', 'diamants', 'rombes', 'diamonts', 'diamonds', 'corazones', 'corazón', 'cors', 'cor', 'heart',\n",
    "              'hearts']]\n",
    "\n",
    "\n",
    "\n",
    "saliencias_8 = [['instrucciones', 'instructions', 'instruccions', 'escrita', 'written', 'notas', 'notes', 'pistas', 'pista',\n",
    "                'pistas', 'clues', 'detective', 'detective', 'tahur', 'taur', 'tahúr', 'taúr', 'trampas', 'tramposo',\n",
    "                'trampós', 'cardshark', 'expresions', 'acciones', 'misatges', 'missatge', 'missatges', 'mensaje', 'mensajes', 'messages',\n",
    "                'frases', 'escrites', 'escritas', 'órdenes', 'ordres', 'indicacions', 'indicaciones', 'tinta', 'ink',\n",
    "                'marca', 'marcada', 'decía', 'manda', 'letras', 'encuentra', 'historia', 'història', 'diciendo',\n",
    "                'pasos', 'steps', 'seguir', 'habla', 'información', 'informacion', 'chiven', 'chivan', 'xiven', 'guiant',\n",
    "                'guiar', 'guien', 'escrit', 'escrites', 'signes', 'paraules', 'lletres', 'palabras', 'anecdotas', 'textos',\n",
    "                'escrito', 'anotacions', 'rotulador', 'escritos', 'textes', 'missagtes', 'pistes', 'habladora', 'dibujado',\n",
    "                'marcas', 'dice', 'decía', 'decia', 'notaciones', 'paso'],\n",
    "               ['sube', 'subía', 'subia', 'subir', 'raise', 'raised', 'puja', 'surt', 'pujava', 'sortia', 'salia', 'demás',\n",
    "                'demés', 'gritar', 'cridar', 'gritaba', 'cariño', 'carinyu', 'amor', 'love', 'ascendió', 'ascendía', 'ascender',\n",
    "               'eleva', 'pujant', 'sale', 'sola', 'pujaven', 'llamar', 'subida', 'pujar', 'emergeix', 'suba', 'ascensor',\n",
    "               'elevar'],\n",
    "                ['as','ace', 'dos', 'two', 'tres', 'three', 'cuatro', 'quatre', 'four', 'cinc', 'cinco', 'five', 'seis', \n",
    "              'sis', 'six', 'siete', 'set', 'seven', 'ocho', 'vuit', 'eight', 'nueve', 'nou', 'nine', 'diez',\n",
    "              'deu', 'ten', 'jota', 'jotas', 'jack', 'dama', 'damas', 'reina', 'reinas', 'queen', 'rey', 'rei', 'reis', 'reyes', \n",
    "               'king', 'picas', 'piques', 'spades', 'treboles', 'tréboles', 'trebol', 'trèbol', 'trèbols', 'trebols', 'culbs',\n",
    "              'diamantes', 'rombos', 'diamants', 'rombes', 'diamonts', 'diamonds', 'corazones', 'corazón', 'cors', 'cor', 'heart',\n",
    "              'hearts'],\n",
    "               ['chico', 'chica', 'raquel', 'espectador', 'espectadora']]\n",
    "\n",
    "\n",
    "#8- Doncs recordo el joc de cartes amb frases escrites, que crec que va ser el joc final. \n",
    "\n",
    "###                \n",
    "Saliencias_words={}\n",
    "Saliencias_words['1']=saliencias_1\n",
    "Saliencias_words['2']=saliencias_2\n",
    "Saliencias_words['3']=saliencias_3\n",
    "Saliencias_words['4']=saliencias_4\n",
    "Saliencias_words['5']=saliencias_5\n",
    "Saliencias_words['6']=saliencias_6\n",
    "Saliencias_words['7']=saliencias_7\n",
    "Saliencias_words['8']=saliencias_8\n",
    "\n",
    "\n",
    "###\n",
    "Saliencias_titles={}\n",
    "Saliencias_titles['1'] = ['joker', 'estuche', 'montones', 'color', 'encore', 'carta1', 'persona1']    \n",
    "Saliencias_titles['2'] = ['frotar', 'dinerito', 'carta2', 'persona2', 'oportunidad', 'desaparecer', 'oreja']  \n",
    "Saliencias_titles['3'] = ['tapadas', 'viajes']  \n",
    "Saliencias_titles['4'] = ['alma', 'predicción', 'carta4', 'persona4'] \n",
    "Saliencias_titles['5'] = ['material', 'vaso', 'mesa', 'manos', 'salian'] \n",
    "Saliencias_titles['6'] = ['deletreo', 'tres', 'española', 'cualquiera', 'fallido', 'persona6'] \n",
    "Saliencias_titles['7'] = ['blancas', 'granada', 'tiempo', 'reunión', 'carta7'] \n",
    "Saliencias_titles['8'] = ['instrucciones', 'sube', 'carta8', 'persona8'] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_saliencias(text, efecto_): #### le doy el texto completo y el numero de efecto del que quiero la saliencia\n",
    "    #### divide el texto en frases y agrupa estas frases en efectos\n",
    "    #### luego analiza las frases del efecto que le hemos dicho (las del diccionario con '2' y busca saliencias)\n",
    "    efectos, list_words = effects_detected(text)\n",
    "    sentences, dict_sentences = separate_sentences_by_effect(text) ## frases agrupadas por efecto\n",
    "    #######\n",
    "    saliencias_txt = []  \n",
    "    if efecto_ not in ['22', '23', '0', '9']: ## most of the cases\n",
    "        eff_sentences = dict_sentences.get(efecto_)   \n",
    "        if eff_sentences:\n",
    "            for sent_ in dict_sentences[efecto_]: ## each sentence by separate\n",
    "                for idx, salience_list in enumerate(Saliencias_words[efecto_]): \n",
    "                    ## permite que una misma saliencia se recuerde mas de una vez si esta en distintas frases del mismo efecto.\n",
    "                    ## salience_list es una lista con todas las palabras usadas para buscar una slaiencia específica.\n",
    "                    ## se buscan todas las saliencias del efecto en cada frase (solo las de ese efecto!)\n",
    "                    if any(word in sent_.split(' ') for word in salience_list): \n",
    "                        #solo que haya 1 plabra de la lista en esa frase ya esta la saliencia (si hay 5 de ellas, solo se guarda 1)\n",
    "                        saliencias_txt.append(Saliencias_titles[efecto_][idx])\n",
    "                ####\n",
    "                todas_palabras = list(itertools.chain.from_iterable(Saliencias_words[efecto_]))\n",
    "                if any(word in sent_.split(' ') for word in todas_palabras) == False:\n",
    "                    ## si en una frase no hay ninguna palabra de ninguna slaiencia, guarda 'otro'\n",
    "                    ## problema: te puedes dejar saliencias (mal escritas) si ya ha encontrado alguna otra slaiencia en la misma frase\n",
    "                    saliencias_txt.append('otro') \n",
    "        ##\n",
    "        ### unique() en saliencias_txt?? o permitir que haya una saliencia mas de una vez?? \n",
    "        ### De momento, se permiten repetidas sólo si están en frases distintas ('división memoria')  \n",
    "        else: ## if efecto_ is not in the dictionary of sentences (eff_sentences is nothing)\n",
    "            saliencias_txt=[]\n",
    "    \n",
    "    \n",
    "    if efecto_ in ['22', '23', '0', '9']:\n",
    "        if efecto_ in efectos:\n",
    "            if efecto_ == '22':\n",
    "                saliencias_txt.append('monedón')\n",
    "            elif efecto_ == '23':\n",
    "                saliencias_txt.append('técnico')\n",
    "            elif efecto_ == '0':\n",
    "                saliencias_txt.append('m_interrogante')\n",
    "            elif efecto_ == '9':\n",
    "                saliencias_txt.append('c_interrogante')\n",
    "            \n",
    "    \n",
    "        \n",
    "    ##        \n",
    "    return saliencias_txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear matriz de análisis (yendo fila a fila en el excel)\n",
    "standard_ = [1,2,2,2,3,4,5,6,7,8,0,9]\n",
    "reversed_ = [8,7,6,5,4,3,2,2,2,1,0,9]\n",
    "orders={'standard':standard_, 'reversed':reversed_}\n",
    "\n",
    "all_subjs=[]\n",
    "\n",
    "\n",
    "\n",
    "for s in range(len(df_data)): ### hayq ue poner las tres hojas en una sola, una debajo de otra\n",
    "    #print(s)\n",
    "    times_with_resp = [type(df_data.iloc[s][['justo después', '10 días después', '1 mes y medio después', '4 meses y medio después']][x])==str for x in range(4)]\n",
    "    n_times_reported = len(times_with_resp) \n",
    "    if n_times_reported>1:\n",
    "        subj_frames=[]\n",
    "    \n",
    "    ### Si no contestan, no está en el análisis (todo son 1 si recuerdo o 0 si no recuerdo)\n",
    "    if times_with_resp==[True, False, False, False]:\n",
    "        times_rep = [1]\n",
    "    if times_with_resp==[True, True, False, False]:\n",
    "        times_rep = [1,2]\n",
    "    if times_with_resp==[True, False, True, False]:\n",
    "        times_rep = [1,3]\n",
    "    if times_with_resp==[True, False, False, True]:\n",
    "        times_rep = [1,4]\n",
    "    if times_with_resp==[False, True, False, True]:\n",
    "        times_rep = [2,4] \n",
    "    if times_with_resp==[False, False, True, True]:\n",
    "        times_rep = [3,4]            \n",
    "    if times_with_resp==[True, True, True, False]:\n",
    "        times_rep = [1,2,3]\n",
    "    if times_with_resp==[True, True, False, True]:\n",
    "        times_rep = [1,2, 4]\n",
    "    if times_with_resp==[True, False, True, True]:\n",
    "        times_rep = [1,3, 4]\n",
    "    if times_with_resp==[True, True, True, True]:\n",
    "        times_rep = [1, 2, 3, 4]\n",
    "        \n",
    "    for t in times_rep:\n",
    "        data_t = np.zeros((12,6))\n",
    "        data_t[:,1] = [1,2,22,23,3,4,5,6,7,8,0,9] # lista de juegos\n",
    "        #data_t[:,2] = df_data.iloc[s].asiento # asiento\n",
    "        horario = df_data.iloc[s]['session']\n",
    "        #\n",
    "        if horario==16:\n",
    "            sess=1\n",
    "            order='standard'\n",
    "        elif horario==17:\n",
    "            sess=2\n",
    "            order='reversed'\n",
    "        elif horario==19:\n",
    "            sess=3\n",
    "            order='standard'\n",
    "        data_t[:,2] = sess #horario\n",
    "        data_t[:,3] = s ### subject number\n",
    "        data_t[:,4] = orders[order]\n",
    "        data_t[:,5] = t\n",
    "        ##### Recuerdo y Saliencias\n",
    "        if t==1:\n",
    "            col_saliencias = 'justo después'\n",
    "        elif t==2:\n",
    "            col_saliencias ='10 días después'\n",
    "        elif t==3:\n",
    "            col_saliencias = '1 mes y medio después'\n",
    "        elif t==4:\n",
    "            col_saliencias = '4 meses y medio después'\n",
    "        ##\n",
    "        text = df_data.iloc[s][col_saliencias]\n",
    "        efectos = effects_detected(text)[0]\n",
    "        all_efectos = np.array(['1', '2', '22', '23', '3', '4', '5', '6', '7', '8', '0', '9'])\n",
    "        recuerdo = np.isin(all_efectos, efectos)*1\n",
    "        data_t[:,0]=recuerdo \n",
    "        saliencias = [extract_saliencias(text, eff) for eff in all_efectos]\n",
    "       \n",
    "\n",
    "        data_t=pd.DataFrame(data_t)\n",
    "        data_t.columns=['recuerdo', 'juego', 'session', 'subj', 'orden', 'tiempo']    \n",
    "        data_t['saliencias'] = saliencias\n",
    "        #\n",
    "        #data_t['nombre'] = df_data.iloc[s]['nombre y apellidos']\n",
    "        if n_times_reported>1:\n",
    "            subj_frames.append(data_t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if n_times_reported>1:\n",
    "        subj = pd.concat(subj_frames)\n",
    "    else:\n",
    "        subj = data_t\n",
    "\n",
    "\n",
    "    all_subjs.append(subj)\n",
    "\n",
    "\n",
    "\n",
    "df_ = pd.concat(all_subjs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## asignacion de numero de saliencias por detección\n",
    "df_['n_saliencias'] = [len(df_['saliencias'].iloc[i]) for i in range(0, len(df_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:36: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:39: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:42: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:45: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:48: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "#### Changes\n",
    "df_ = df_.loc[(df_['subj']!=100)]\n",
    "df_.reset_index();\n",
    "\n",
    "idx = df_.loc[(df_['subj']==115) & (df_['session']==3) & (df_['tiempo']==2) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==26) & (df_['session']==1) & (df_['tiempo']==1) & (df_['juego']==6)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['carta6']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==26) & (df_['session']==1) & (df_['tiempo']==2) & (df_['juego']==6)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['carta6', 'española', 'persona6']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==26) & (df_['session']==1) & (df_['tiempo']==3) & (df_['juego']==6)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['carta6', 'española']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==112) & (df_['session']==3) & (df_['tiempo']==1) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==36) & (df_['session']==1) & (df_['tiempo']==1) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==36) & (df_['session']==1) & (df_['tiempo']==2) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker', 'color']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==36) & (df_['session']==1) & (df_['tiempo']==3) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker', 'color']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==36) & (df_['session']==1) & (df_['tiempo']==4) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==45) & (df_['session']==2) & (df_['tiempo']==2) & (df_['juego']==6)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['carta6']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==45) & (df_['session']==2) & (df_['tiempo']==3) & (df_['juego']==6)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['carta6', 'persona6']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==61) & (df_['session']==2) & (df_['tiempo']==1) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['color', 'joker']);\n",
    "\n",
    "idx =  df_.loc[(df_['subj']==84) & (df_['session']==3) & (df_['tiempo']==1) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['color', 'montones', 'encore']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==31) & (df_['session']==1) & (df_['tiempo']==2) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker']);\n",
    "\n",
    "idx = df_.loc[(df_['subj']==31) & (df_['session']==1) & (df_['tiempo']==3) & (df_['juego']==1)].index[0]\n",
    "df_.set_value(idx, 'saliencias' , ['joker']);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_excel('df_proces.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
